{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "#from live_loss_plot import PlotLosses\n",
    "\n",
    "# Keras layers\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Dropout, BatchNormalization, GlobalMaxPool2D\n",
    "\n",
    "import tensorflowjs as tfjs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(names, amount): #pobiera dane, argumenty: tablica nazw klas, ilośc danych\n",
    "    data_t = {}\n",
    "    data = np.load(\"/home/user/data/\"+names[0]+\".npy\")\n",
    "    X_train = data[0:amount].reshape(-1, 28, 28, 1).astype('float32')/255    \n",
    "    Y_train = amount*[0]\n",
    "    X_test = data[amount:2*amount].reshape(-1, 28, 28, 1).astype('float32')/255\n",
    "    Y_test = amount*[0]\n",
    "    for i in range(len(names)-1):\n",
    "        data = np.load(\"/home/user/data/\"+names[i+1]+\".npy\")\n",
    "        data_t = data[0:amount].reshape(-1, 28, 28, 1).astype('float32')/255\n",
    "        X_train = np.concatenate((X_train, data_t), 0)\n",
    "        Y_train = np.concatenate((Y_train, amount*[i]),0)\n",
    "        \n",
    "        data_t = data[amount:2*amount].reshape(-1, 28, 28, 1).astype('float32')/255\n",
    "        X_test = np.concatenate((X_test, data_t), 0)\n",
    "        Y_test = np.concatenate((Y_test, amount*[i]),0)\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/user/data/airplane.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d81ed09a863c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'airplane'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'onion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-cab5fddc2832>\u001b[0m in \u001b[0;36mdata_load\u001b[0;34m(names, amount)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#pobiera dane, argumenty: tablica nazw klas, ilośc danych\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/user/data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mamount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weronika/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/user/data/airplane.npy'"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_load(['airplane', 'onion'], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0644 - acc: 0.9870 - val_loss: 4.4273e-05 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 4.8632e-05 - acc: 1.0000 - val_loss: 1.6905e-05 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 4.8083e-05 - acc: 1.0000 - val_loss: 1.4089e-05 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 3.8787e-05 - acc: 1.0000 - val_loss: 1.1945e-05 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 4.0841e-05 - acc: 1.0000 - val_loss: 9.8737e-06 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.6779e-05 - acc: 1.0000 - val_loss: 8.8486e-06 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3076e-05 - acc: 1.0000 - val_loss: 7.5786e-06 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0949e-05 - acc: 1.0000 - val_loss: 7.2375e-06 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.9949e-05 - acc: 1.0000 - val_loss: 6.1937e-06 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2243e-05 - acc: 1.0000 - val_loss: 4.8884e-06 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5103e-05 - acc: 1.0000 - val_loss: 4.3280e-06 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6535e-05 - acc: 1.0000 - val_loss: 3.6900e-06 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1758e-05 - acc: 1.0000 - val_loss: 3.2745e-06 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2772e-05 - acc: 1.0000 - val_loss: 2.8713e-06 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 8.1439e-06 - acc: 1.0000 - val_loss: 2.7402e-06 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 9.9008e-06 - acc: 1.0000 - val_loss: 1.7411e-06 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.7293e-06 - acc: 1.0000 - val_loss: 1.5946e-06 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 4.6916e-06 - acc: 1.0000 - val_loss: 1.4859e-06 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.2571e-06 - acc: 1.0000 - val_loss: 1.3830e-06 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.4679e-06 - acc: 1.0000 - val_loss: 1.2562e-06 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe67ac97550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, (5, 5), activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=20,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('onions_vs_pineapples.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfjs.converters.save_keras_model(model,'/home/user/ex/notebooks/tfjs' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
